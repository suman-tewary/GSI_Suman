{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbfa130-82f2-4eda-9e2d-7796868a856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Day 1...\n",
      "Processing Day 2...\n",
      "Processing Day 3...\n",
      "Processing Day 4...\n",
      "Processing Day 5...\n",
      "Processing Day 6...\n",
      "Word report saved to pca_report_green.docx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "def perform_pca(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    data_cleaned = data.dropna()\n",
    "    \n",
    "    # Extract reflectance values (exclude non-numeric columns like sample IDs)\n",
    "    reflectance_matrix = data_cleaned.iloc[:, 1:].values  # Adjust slicing as per your dataset\n",
    "    wavelengths = data_cleaned.columns[1:]  # Extract wavelength column names\n",
    "    \n",
    "    # Normalize the reflectance data (standardize: mean=0, std=1)\n",
    "    reflectance_normalized = (reflectance_matrix - np.mean(reflectance_matrix, axis=0)) / np.std(reflectance_matrix, axis=0)\n",
    "    \n",
    "    # Perform PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(reflectance_normalized)\n",
    "    \n",
    "    # Extract explained variance and principal components\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    principal_components = pca.components_\n",
    "    \n",
    "    # Get top 10 wavelengths for each of the first 5 PCs\n",
    "    pc_results = {}\n",
    "    for pc_index in range(5):\n",
    "        loading_scores = principal_components[pc_index]  # Loadings for the current PC\n",
    "        important_wavelengths = sorted(zip(wavelengths, loading_scores), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "        pc_results[f\"PC{pc_index + 1}\"] = important_wavelengths\n",
    "    \n",
    "    return explained_variance[:5], pc_results\n",
    "\n",
    "def generate_word_report(file_paths, output_docx):\n",
    "    # Initialize report data\n",
    "    report_pc_percentages = []\n",
    "    report_pc_wavelengths = []\n",
    "    \n",
    "    # Process each file (day-by-day)\n",
    "    for day, file_path in enumerate(file_paths, start=1):\n",
    "        print(f\"Processing Day {day}...\")\n",
    "        explained_variance, pc_results = perform_pca(file_path)\n",
    "        \n",
    "        # Add explained variance percentages to the report\n",
    "        report_pc_percentages.append([f\"Day {day}\"] + [f\"{variance * 100:.2f}%\" for variance in explained_variance])\n",
    "        \n",
    "        # Add top 10 wavelengths for each PC to the report\n",
    "        day_wavelengths = {}\n",
    "        for pc, wavelengths in pc_results.items():\n",
    "            day_wavelengths[pc] = wavelengths\n",
    "        report_pc_wavelengths.append((f\"Day {day}\", day_wavelengths))\n",
    "    \n",
    "    # Create a Word document\n",
    "    doc = Document()\n",
    "    \n",
    "    # Add title\n",
    "    doc.add_heading(\"PCA Report: Day-by-Day Analysis\", 0)\n",
    "    \n",
    "    # Add explained variance table\n",
    "    doc.add_heading(\"Explained Variance Percentages\", level=1)\n",
    "    pc_percentage_df = pd.DataFrame(report_pc_percentages, columns=[\"Day\", \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\"])\n",
    "    table = doc.add_table(rows=1, cols=6)\n",
    "    table.style = \"Table Grid\"\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = \"Day\"\n",
    "    hdr_cells[1].text = \"PC1\"\n",
    "    hdr_cells[2].text = \"PC2\"\n",
    "    hdr_cells[3].text = \"PC3\"\n",
    "    hdr_cells[4].text = \"PC4\"\n",
    "    hdr_cells[5].text = \"PC5\"\n",
    "    for row in pc_percentage_df.values:\n",
    "        row_cells = table.add_row().cells\n",
    "        for i, value in enumerate(row):\n",
    "            row_cells[i].text = value\n",
    "    \n",
    "    # Add top 10 wavelengths for each day\n",
    "    doc.add_heading(\"Top 10 Wavelengths for Each Principal Component\", level=1)\n",
    "    for day, wavelengths in report_pc_wavelengths:\n",
    "        doc.add_heading(f\"{day}:\", level=2)\n",
    "        for pc, values in wavelengths.items():\n",
    "            doc.add_heading(f\"{pc}:\", level=3)\n",
    "            table = doc.add_table(rows=1, cols=2)\n",
    "            table.style = \"Table Grid\"\n",
    "            hdr_cells = table.rows[0].cells\n",
    "            hdr_cells[0].text = \"Wavelength\"\n",
    "            hdr_cells[1].text = \"Contribution\"\n",
    "            for wavelength, score in values:\n",
    "                row_cells = table.add_row().cells\n",
    "                row_cells[0].text = wavelength\n",
    "                row_cells[1].text = f\"{score:.4f}\"\n",
    "    \n",
    "    # Save the Word document\n",
    "    doc.save(output_docx)\n",
    "    print(f\"Word report saved to {output_docx}\")\n",
    "\n",
    "# Example usage\n",
    "file_paths = [\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 09-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 12-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 23-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 31-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 06-09-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 03-10-24.csv\"\n",
    "]\n",
    "generate_word_report(file_paths, \"pca_report_green.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f4109c-cbf6-476a-86e0-ebc5f9b8e013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Day 1...\n",
      "Processing Day 2...\n",
      "Processing Day 3...\n",
      "Processing Day 4...\n",
      "Processing Day 5...\n",
      "Processing Day 6...\n",
      "Word report saved to pca_report_red.docx\n"
     ]
    }
   ],
   "source": [
    "file_paths = [\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file09-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file12-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file23-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file31-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file06-09-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file 03-10-24.csv\"\n",
    "]\n",
    "generate_word_report(file_paths, \"pca_report_red.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504776ad-2524-464e-ab8c-95b502678f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Day 1...\n",
      "Processing Day 2...\n",
      "Processing Day 3...\n",
      "Processing Day 4...\n",
      "Processing Day 5...\n",
      "Processing Day 6...\n",
      "Word report saved to pca_report_green1.docx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "def perform_pca(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    data_cleaned = data.dropna()\n",
    "    \n",
    "    # Extract reflectance values (exclude non-numeric columns like sample IDs)\n",
    "    reflectance_matrix = data_cleaned.iloc[:, 1:].values  # Adjust slicing as per your dataset\n",
    "    wavelengths = data_cleaned.columns[1:]  # Extract wavelength column names\n",
    "    \n",
    "    # Normalize the reflectance data (standardize: mean=0, std=1)\n",
    "    reflectance_normalized = (reflectance_matrix - np.mean(reflectance_matrix, axis=0)) / np.std(reflectance_matrix, axis=0)\n",
    "    \n",
    "    # Perform PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(reflectance_normalized)\n",
    "    \n",
    "    # Extract explained variance and principal components\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    principal_components = pca.components_\n",
    "    \n",
    "    # Get top 10 wavelengths for each of the first 5 PCs\n",
    "    pc_results = {}\n",
    "    for pc_index in range(5):\n",
    "        loading_scores = principal_components[pc_index]  # Loadings for the current PC\n",
    "        important_wavelengths = sorted(zip(wavelengths, loading_scores), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "        pc_results[f\"PC{pc_index + 1}\"] = [wavelength for wavelength, _ in important_wavelengths]\n",
    "    \n",
    "    return explained_variance[:5], pc_results\n",
    "\n",
    "def generate_word_report(file_paths, output_docx):\n",
    "    # Initialize report data\n",
    "    report_pc_percentages = []\n",
    "    report_pc_wavelengths = []\n",
    "    \n",
    "    # Process each file (day-by-day)\n",
    "    for day, file_path in enumerate(file_paths, start=1):\n",
    "        print(f\"Processing Day {day}...\")\n",
    "        explained_variance, pc_results = perform_pca(file_path)\n",
    "        \n",
    "        # Add explained variance percentages to the report\n",
    "        report_pc_percentages.append([f\"Day {day}\"] + [f\"{variance * 100:.2f}%\" for variance in explained_variance])\n",
    "        \n",
    "        # Add top 10 wavelengths for each PC to the report\n",
    "        report_pc_wavelengths.append((f\"Day {day}\", pc_results))\n",
    "    \n",
    "    # Create a Word document\n",
    "    doc = Document()\n",
    "    \n",
    "    # Add title\n",
    "    doc.add_heading(\"PCA Report: Day-by-Day Analysis\", 0)\n",
    "    \n",
    "    # Add explained variance table\n",
    "    doc.add_heading(\"Explained Variance Percentages\", level=1)\n",
    "    pc_percentage_df = pd.DataFrame(report_pc_percentages, columns=[\"Day\", \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\"])\n",
    "    table = doc.add_table(rows=1, cols=6)\n",
    "    table.style = \"Table Grid\"\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = \"Day\"\n",
    "    hdr_cells[1].text = \"PC1\"\n",
    "    hdr_cells[2].text = \"PC2\"\n",
    "    hdr_cells[3].text = \"PC3\"\n",
    "    hdr_cells[4].text = \"PC4\"\n",
    "    hdr_cells[5].text = \"PC5\"\n",
    "    for row in pc_percentage_df.values:\n",
    "        row_cells = table.add_row().cells\n",
    "        for i, value in enumerate(row):\n",
    "            row_cells[i].text = value\n",
    "    \n",
    "    # Add top 10 wavelengths for each PC in a single table\n",
    "    doc.add_heading(\"Top 10 Wavelengths for Each Principal Component (Day-by-Day)\", level=1)\n",
    "    \n",
    "    # Create a table for each PC\n",
    "    for pc_index in range(5):\n",
    "        pc = f\"PC{pc_index + 1}\"\n",
    "        doc.add_heading(f\"{pc} Wavelengths\", level=2)\n",
    "        \n",
    "        # Create a table with days as columns\n",
    "        table = doc.add_table(rows=11, cols=len(file_paths))  # 10 wavelengths + header row\n",
    "        table.style = \"Table Grid\"\n",
    "        \n",
    "        # Add headers for each day\n",
    "        for col_idx, (day, _) in enumerate(report_pc_wavelengths):\n",
    "            table.cell(0, col_idx).text = day\n",
    "        \n",
    "        # Add top 10 wavelengths for each day\n",
    "        for row_idx in range(1, 11):  # Rows for wavelengths 1-10\n",
    "            for col_idx, (_, wavelengths) in enumerate(report_pc_wavelengths):\n",
    "                wavelength = wavelengths[pc][row_idx - 1]\n",
    "                table.cell(row_idx, col_idx).text = wavelength\n",
    "    \n",
    "    # Save the Word document\n",
    "    doc.save(output_docx)\n",
    "    print(f\"Word report saved to {output_docx}\")\n",
    "\n",
    "# Example usage\n",
    "file_paths = [\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 09-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 12-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 23-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 31-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 06-09-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\Filter data of Green apple\\\\Merged data\\\\merged_wavelength_reflectance 03-10-24.csv\"\n",
    "]\n",
    "generate_word_report(file_paths, \"pca_report_green1.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb257642-d3aa-4c6a-833e-dbf4b41f79ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Day 1...\n",
      "Processing Day 2...\n",
      "Processing Day 3...\n",
      "Processing Day 4...\n",
      "Processing Day 5...\n",
      "Processing Day 6...\n",
      "Word report saved to pca_report_red1.docx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "def perform_pca(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    data_cleaned = data.dropna()\n",
    "    \n",
    "    # Extract reflectance values (exclude non-numeric columns like sample IDs)\n",
    "    reflectance_matrix = data_cleaned.iloc[:, 1:].values  # Adjust slicing as per your dataset\n",
    "    wavelengths = data_cleaned.columns[1:]  # Extract wavelength column names\n",
    "    \n",
    "    # Normalize the reflectance data (standardize: mean=0, std=1)\n",
    "    reflectance_normalized = (reflectance_matrix - np.mean(reflectance_matrix, axis=0)) / np.std(reflectance_matrix, axis=0)\n",
    "    \n",
    "    # Perform PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(reflectance_normalized)\n",
    "    \n",
    "    # Extract explained variance and principal components\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    principal_components = pca.components_\n",
    "    \n",
    "    # Get top 10 wavelengths for each of the first 5 PCs\n",
    "    pc_results = {}\n",
    "    for pc_index in range(5):\n",
    "        loading_scores = principal_components[pc_index]  # Loadings for the current PC\n",
    "        important_wavelengths = sorted(zip(wavelengths, loading_scores), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "        pc_results[f\"PC{pc_index + 1}\"] = [wavelength for wavelength, _ in important_wavelengths]\n",
    "    \n",
    "    return explained_variance[:5], pc_results\n",
    "\n",
    "def generate_word_report(file_paths, output_docx):\n",
    "    # Initialize report data\n",
    "    report_pc_percentages = []\n",
    "    report_pc_wavelengths = []\n",
    "    \n",
    "    # Process each file (day-by-day)\n",
    "    for day, file_path in enumerate(file_paths, start=1):\n",
    "        print(f\"Processing Day {day}...\")\n",
    "        explained_variance, pc_results = perform_pca(file_path)\n",
    "        \n",
    "        # Add explained variance percentages to the report\n",
    "        report_pc_percentages.append([f\"Day {day}\"] + [f\"{variance * 100:.2f}%\" for variance in explained_variance])\n",
    "        \n",
    "        # Add top 10 wavelengths for each PC to the report\n",
    "        report_pc_wavelengths.append((f\"Day {day}\", pc_results))\n",
    "    \n",
    "    # Create a Word document\n",
    "    doc = Document()\n",
    "    \n",
    "    # Add title\n",
    "    doc.add_heading(\"PCA Report: Day-by-Day Analysis\", 0)\n",
    "    \n",
    "    # Add explained variance table\n",
    "    doc.add_heading(\"Explained Variance Percentages\", level=1)\n",
    "    pc_percentage_df = pd.DataFrame(report_pc_percentages, columns=[\"Day\", \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\"])\n",
    "    table = doc.add_table(rows=1, cols=6)\n",
    "    table.style = \"Table Grid\"\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = \"Day\"\n",
    "    hdr_cells[1].text = \"PC1\"\n",
    "    hdr_cells[2].text = \"PC2\"\n",
    "    hdr_cells[3].text = \"PC3\"\n",
    "    hdr_cells[4].text = \"PC4\"\n",
    "    hdr_cells[5].text = \"PC5\"\n",
    "    for row in pc_percentage_df.values:\n",
    "        row_cells = table.add_row().cells\n",
    "        for i, value in enumerate(row):\n",
    "            row_cells[i].text = value\n",
    "    \n",
    "    # Add top 10 wavelengths for each PC in a single table\n",
    "    doc.add_heading(\"Top 10 Wavelengths for Each Principal Component (Day-by-Day)\", level=1)\n",
    "    \n",
    "    # Create a table for each PC\n",
    "    for pc_index in range(5):\n",
    "        pc = f\"PC{pc_index + 1}\"\n",
    "        doc.add_heading(f\"{pc} Wavelengths\", level=2)\n",
    "        \n",
    "        # Create a table with days as columns\n",
    "        table = doc.add_table(rows=11, cols=len(file_paths))  # 10 wavelengths + header row\n",
    "        table.style = \"Table Grid\"\n",
    "        \n",
    "        # Add headers for each day\n",
    "        for col_idx, (day, _) in enumerate(report_pc_wavelengths):\n",
    "            table.cell(0, col_idx).text = day\n",
    "        \n",
    "        # Add top 10 wavelengths for each day\n",
    "        for row_idx in range(1, 11):  # Rows for wavelengths 1-10\n",
    "            for col_idx, (_, wavelengths) in enumerate(report_pc_wavelengths):\n",
    "                wavelength = wavelengths[pc][row_idx - 1]\n",
    "                table.cell(row_idx, col_idx).text = wavelength\n",
    "    \n",
    "    # Save the Word document\n",
    "    doc.save(output_docx)\n",
    "    print(f\"Word report saved to {output_docx}\")\n",
    "\n",
    "file_paths = [\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file09-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file12-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file23-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file31-07-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file06-09-24.csv\",\n",
    "    \"C:\\\\Users\\\\sumat\\\\Desktop\\\\GSI Suman\\\\pravakar\\\\filtered data of red apple\\\\merged data\\\\merged_file 03-10-24.csv\"\n",
    "]\n",
    "generate_word_report(file_paths, \"pca_report_red1.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de31bf5-3a58-4be1-b41f-41a3eccb0e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
